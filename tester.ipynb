{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import subprocess\n",
    "\n",
    "class Parser():\n",
    "\n",
    "    def __init__(self, path):\n",
    "        \n",
    "        with open(path, 'r') as f:\n",
    "            self.contract = f.readlines()\n",
    "        self.path=path\n",
    "        self.functions = []\n",
    "        self.semantic_vectors = []\n",
    "        self.output_dir = 'parsed_contracts'\n",
    "        self.contract_name = path[:-4]\n",
    "        self.slither_output=\"\"\n",
    "        self.echidna_output=\"\"\n",
    "\n",
    "    def parse_contract_to_functions(self):\n",
    "\n",
    "        curr_fun = ''\n",
    "        reading_function = False\n",
    "        bracket_balance = None\n",
    "        first_line=0\n",
    "        end_line=0\n",
    "        for index,line in enumerate(self.contract):\n",
    "            if 'function' in line:\n",
    "                first_line=index\n",
    "                curr_fun += line\n",
    "                bracket_balance = 1\n",
    "                reading_function = True\n",
    "            elif reading_function:\n",
    "                left_bracket = line.count('{')\n",
    "                right_bracket = line.count('}')\n",
    "\n",
    "                bracket_balance += left_bracket\n",
    "                bracket_balance -= right_bracket\n",
    "\n",
    "                curr_fun += line\n",
    "                if bracket_balance == 0:\n",
    "                    end_line=index\n",
    "                    self.functions.append([curr_fun,first_line,end_line])\n",
    "                    curr_fun = ''\n",
    "                    bracket_balance = None\n",
    "                    reading_function = False\n",
    "\n",
    "    def get_semantic_vectors(self):\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "        model = AutoModel.from_pretrained(\"microsoft/codebert-base\")\n",
    "\n",
    "        for input_text in self.functions:\n",
    "            self.get_vector_from_input(tokenizer, model, input_text[0])\n",
    "\n",
    "        self.semantic_vectors_whitening()\n",
    "        # self.save_functions_and_vectors()\n",
    "\n",
    "    def get_vector_from_input(self, tokenizer, model, input_text):\n",
    "        input_ids = tokenizer.encode(input_text, return_tensors=\"pt\", \n",
    "                                     max_length=512, truncation=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids)\n",
    "            semantic_vector = outputs.last_hidden_state.mean(dim=1) \n",
    "            self.semantic_vectors.append(semantic_vector.squeeze().numpy())\n",
    "        \n",
    "    def semantic_vectors_whitening(self):\n",
    "        vectors = np.asarray(self.semantic_vectors)\n",
    "        covariance_matrix = np.cov(vectors, rowvar=False)\n",
    "        eigenvalues, eigenvectors = np.linalg.eigh(covariance_matrix)\n",
    "        whitening_matrix = np.dot(np.dot(eigenvectors, np.diag(1.0 / np.sqrt(eigenvalues + 1e-5))), eigenvectors.T)\n",
    "\n",
    "        whitened_vectors = np.dot(vectors, whitening_matrix)\n",
    "        mean = np.mean(whitened_vectors, axis=0)\n",
    "        std = np.std(whitened_vectors, axis=0)\n",
    "\n",
    "        normalized_whitened_vectors = (whitened_vectors - mean) / std\n",
    "        self.semantic_vectors = normalized_whitened_vectors\n",
    "\n",
    "    def get_slither_tests(self):\n",
    "        result = subprocess.run(['slither', self.path], \n",
    "                stdout=subprocess.PIPE,\n",
    "                stderr=subprocess.PIPE)\n",
    "        output=result.stderr.decode('cp1252')\n",
    "        self.slither_output=output\n",
    "    \n",
    "    def get_echidna_tests(self):\n",
    "        result = subprocess.run(['echidna',self.path], \n",
    "                        stdout=subprocess.PIPE,\n",
    "                        stderr=subprocess.PIPE)\n",
    "        output=result.stderr.decode()\n",
    "        self.echidna_output=output\n",
    "    def save_functions_and_vectors(self):\n",
    "        if not os.path.exists(os.path.join(self.output_dir, self.contract_name, 'functions')):\n",
    "            os.makedirs(os.path.join(self.output_dir, self.contract_name, 'functions'))\n",
    "\n",
    "        if not os.path.exists(os.path.join(self.output_dir, self.contract_name, 'semantic_vectors')):\n",
    "            os.makedirs(os.path.join(self.output_dir, self.contract_name, 'semantic_vectors'))\n",
    "        \n",
    "        for i, (fun, vec) in enumerate(zip(self.functions, self.semantic_vectors)):\n",
    "            \n",
    "            with open(os.path.join(self.output_dir, self.contract_name, 'functions', f'{i}.txt'), 'w+')  as f:\n",
    "                f.write(fun[0])\n",
    "\n",
    "            with open(os.path.join(self.output_dir, self.contract_name, 'semantic_vectors', f'{i}.txt'), 'w+') as f:\n",
    "                json.dump(vec.tolist(), f)\n",
    "\n",
    "    def save_tests(self):  \n",
    "        if not os.path.exists(os.path.join(self.output_dir, self.contract_name, 'test_outputs')):\n",
    "            os.makedirs(os.path.join(self.output_dir, self.contract_name, 'test_outputs')) \n",
    "        with open(os.path.join(self.output_dir, self.contract_name, 'test_outputs', 'slither.txt'), 'w+')  as f:\n",
    "            f.write(self.slither_output)\n",
    "        with open(os.path.join(self.output_dir, self.contract_name, 'test_outputs', 'echidna.txt'), 'w+')  as f:\n",
    "            f.write(self.echidna_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = Parser('example2.sol')\n",
    "parser.get_slither_tests()\n",
    "parser.get_echidna_tests()\n",
    "parser.save_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser.save_functions_and_vectors()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smart_contracts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
