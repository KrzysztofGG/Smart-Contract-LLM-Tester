{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "\n",
    "class Parser():\n",
    "\n",
    "    def __init__(self, path):\n",
    "        \n",
    "        with open(path, 'r') as f:\n",
    "            self.contract = f.readlines()\n",
    "\n",
    "        self.functions = []\n",
    "        self.semantic_vectors = []\n",
    "        self.output_dir = 'parsed_contracts'\n",
    "        self.contract_name = path[:-4]\n",
    "\n",
    "    def parse_contract_to_functions(self):\n",
    "\n",
    "        curr_fun = ''\n",
    "        reading_function = False\n",
    "        bracket_balance = None\n",
    "\n",
    "        for line in self.contract:\n",
    "            if 'function' in line:\n",
    "                curr_fun += line\n",
    "                bracket_balance = 1\n",
    "                reading_function = True\n",
    "            elif reading_function:\n",
    "                left_bracket = line.count('{')\n",
    "                right_bracket = line.count('}')\n",
    "\n",
    "                bracket_balance += left_bracket\n",
    "                bracket_balance -= right_bracket\n",
    "\n",
    "                curr_fun += line\n",
    "                if bracket_balance == 0:\n",
    "\n",
    "                    self.functions.append(curr_fun)\n",
    "                    curr_fun = ''\n",
    "\n",
    "                    bracket_balance = None\n",
    "                    reading_function = False\n",
    "\n",
    "    def get_semantic_vectors(self):\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "        model = AutoModel.from_pretrained(\"microsoft/codebert-base\")\n",
    "\n",
    "        for input_text in self.functions:\n",
    "            self.get_vector_from_input(tokenizer, model, input_text)\n",
    "\n",
    "        self.semantic_vectors_whitening()\n",
    "        # self.save_functions_and_vectors()\n",
    "\n",
    "    def get_vector_from_input(self, tokenizer, model, input_text):\n",
    "        input_ids = tokenizer.encode(input_text, return_tensors=\"pt\", \n",
    "                                     max_length=512, truncation=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids)\n",
    "            semantic_vector = outputs.last_hidden_state.mean(dim=1) \n",
    "            self.semantic_vectors.append(semantic_vector.squeeze().numpy())\n",
    "\n",
    "    def semantic_vectors_whitening(self):\n",
    "        vectors = np.asarray(self.semantic_vectors)\n",
    "        covariance_matrix = np.cov(vectors, rowvar=False)\n",
    "        eigenvalues, eigenvectors = np.linalg.eigh(covariance_matrix)\n",
    "        whitening_matrix = np.dot(np.dot(eigenvectors, np.diag(1.0 / np.sqrt(eigenvalues + 1e-5))), eigenvectors.T)\n",
    "\n",
    "        whitened_vectors = np.dot(vectors, whitening_matrix)\n",
    "        mean = np.mean(whitened_vectors, axis=0)\n",
    "        std = np.std(whitened_vectors, axis=0)\n",
    "\n",
    "        normalized_whitened_vectors = (whitened_vectors - mean) / std\n",
    "        self.semantic_vectors = normalized_whitened_vectors\n",
    "\n",
    "    def save_functions_and_vectors(self):\n",
    "        if not os.path.exists(os.path.join(self.output_dir, self.contract_name, 'functions')):\n",
    "            os.makedirs(os.path.join(self.output_dir, self.contract_name, 'functions'))\n",
    "\n",
    "        if not os.path.exists(os.path.join(self.output_dir, self.contract_name, 'semantic_vectors')):\n",
    "            os.makedirs(os.path.join(self.output_dir, self.contract_name, 'semantic_vectors'))\n",
    "        \n",
    "        for i, (fun, vec) in enumerate(zip(self.functions, self.semantic_vectors)):\n",
    "            \n",
    "            with open(os.path.join(self.output_dir, self.contract_name, 'functions', f'{i}.txt'), 'w+')  as f:\n",
    "                f.write(fun)\n",
    "\n",
    "            with open(os.path.join(self.output_dir, self.contract_name, 'semantic_vectors', f'{i}.txt'), 'w+') as f:\n",
    "                json.dump(vec.tolist(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = Parser('example.sol')\n",
    "parser.parse_contract_to_functions()\n",
    "parser.get_semantic_vectors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser.save_functions_and_vectors()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smart_contracts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
